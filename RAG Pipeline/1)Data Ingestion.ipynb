{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion with Document Loaders\n",
    "This script demonstrates how to load raw data from different sources (text files,\n",
    "PDFs, and web pages) using `langchain_community` loaders. \n",
    "Each loader outputs a list of `Document` objects, which can be further processed\n",
    "in downstream pipelines (splitting, embedding, vector stores, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence and Society\n",
      "\n",
      "Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. \n",
      "Today, AI systems are able to recognize speech, translat\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "#Create a loader for a local text file\n",
    "text_loader = TextLoader(\"../data/AI_and_society.txt\")\n",
    "\n",
    "#Actually load the file content into Document objects\n",
    "text_documents = text_loader.load()\n",
    "\n",
    "#`text_documents` is a list of Documents with attributes like `page_content`\n",
    "print(text_documents[0].page_content[:200])  #print the first 200 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gauricchio\\AppData\\Local\\miniconda3\\envs\\genai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages loaded: 15\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "#Create a loader for a PDF file\n",
    "pdf_loader = PyPDFLoader(\"../data/Attention is all you need.pdf\")\n",
    "\n",
    "#Load all pages of the PDF into a list of Documents\n",
    "pdf_documents = pdf_loader.load()\n",
    "\n",
    "print(f\"Number of pages loaded: {len(pdf_documents)}\")\n",
    "print(type(pdf_documents[0]))  #confirm they are Document objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Based Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded from web: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "#Load a single web page as Documents\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.cloudflare.com/it-it/learning/ai/what-is-large-language-model/\",)\n",
    ")\n",
    "\n",
    "web_documents = web_loader.load()\n",
    "print(f\"Documents loaded from web: {len(web_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.cloudflare.com/it-it/learning/ai/what-is-large-language-model/', 'title': 'Just a moment...', 'language': 'en-US'}, page_content='Just a moment...Enable JavaScript and cookies to continue\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Loader with BeautifulSoap Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered documents from web: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "#Optionally filter the HTML DOM to parse only specific classes\n",
    "filtered_web_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.cloudflare.com/it-it/learning/ai/what-is-large-language-model/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-title\", \"post-content\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "filtered_documents = filtered_web_loader.load()\n",
    "print(f\"Filtered documents from web: {len(filtered_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x24cb0dd06d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
